{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, exp\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from n_gram import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he could have said mainland china but he didn t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i hate linking to the right wing daily mail bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>buildings today are built to last about years ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exactly i personally heard of many couples in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my family got a site which was completely surr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Value\n",
       "0    he could have said mainland china but he didn t\n",
       "1  i hate linking to the right wing daily mail bu...\n",
       "2  buildings today are built to last about years ...\n",
       "3  exactly i personally heard of many couples in ...\n",
       "4  my family got a site which was completely surr..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"Dataset/Training/train_data.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_corpus = {} \n",
    "sentence_id = 0\n",
    "for sentence in df['Value']:\n",
    "    tokenized_sentence = []\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = (token for token in tokens if token.isalpha())\n",
    "    tokenized_sentence += tokens\n",
    "    processed_corpus[sentence_id] = tokenized_sentence\n",
    "    sentence_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263000\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_counts = {}\n",
    "unigram_counts[\"<s>\"] = 0\n",
    "unigram_counts[\"</s>\"] = 0\n",
    "for id in processed_corpus:\n",
    "    for token in processed_corpus[id]:\n",
    "        if token not in unigram_counts:\n",
    "            unigram_counts[token] = 0\n",
    "        unigram_counts[token] += 1\n",
    "    unigram_counts[\"<s>\"] += 1\n",
    "    unigram_counts[\"</s>\"] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = train_n_gram(processed_corpus, 1)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all we could do is to reach out to our friends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadly this uphill task and severe competition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i got shammed but an indian professor cause i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my dad is also someone who finds joy in the si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>built roads using unnecessary high interest ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Value\n",
       "0  all we could do is to reach out to our friends...\n",
       "1  sadly this uphill task and severe competition ...\n",
       "2  i got shammed but an indian professor cause i ...\n",
       "3  my dad is also someone who finds joy in the si...\n",
       "4  built roads using unnecessary high interest ch..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"Dataset/Testing/test_data.csv\"\n",
    "df_test = pd.read_csv(filepath)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = {}\n",
    "test_tokens = set()\n",
    "sentence_id = 0\n",
    "num_test_words = 0\n",
    "for sentence in df_test['Value']:\n",
    "    tokenized_sentence = []\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = (token for token in tokens if token.isalpha())\n",
    "    tokenized_sentence += tokens\n",
    "    test_corpus[sentence_id] = tokenized_sentence\n",
    "    num_test_words += 2 + len(tokenized_sentence)\n",
    "    for token in tokenized_sentence:\n",
    "        test_tokens.add(token)\n",
    "    sentence_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 0\n",
    "for token in unigram_counts:\n",
    "    N_train += unigram_counts[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating perplexity\n",
    "\n",
    "prob_uni_words = {}\n",
    "prob_uni_words[\"<s>\"] = unigram_counts[\"<s>\"] / N_train\n",
    "prob_uni_words[\"</s>\"] = unigram_counts[\"</s>\"] / N_train\n",
    "for token in test_tokens:\n",
    "        if token in unigram_counts:\n",
    "            prob_uni_words[token] = unigram_counts[token]/N_train\n",
    "        else:\n",
    "            prob_uni_words[token] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_vocab = 0\n",
    "for i in prob_uni_words:\n",
    "    if(prob_uni_words[i]==0):\n",
    "        out_of_vocab+=1\n",
    "out_of_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = {}\n",
    "ep=1e-15\n",
    "pp = 0\n",
    "for id in test_corpus:\n",
    "    N = 2 + len(test_corpus[id])\n",
    "    temp = log(prob_uni_words[\"<s>\"])\n",
    "    for token in test_corpus[id]:\n",
    "        if(prob_uni_words[token]==0):\n",
    "            temp += log(prob_uni_words[token]+ep)\n",
    "        else:\n",
    "            temp += log(prob_uni_words[token])\n",
    "    temp += log(prob_uni_words[\"</s>\"])\n",
    "    temp = (-temp)/N\n",
    "    perplexity[id] = exp(temp)\n",
    "    pp += perplexity[id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Unigram Model without smoothing is:  10981259472.414888\n"
     ]
    }
   ],
   "source": [
    "Unigram_pp = pp/len(test_corpus)\n",
    "print(\"Perplexity of Unigram Model without smoothing is: \", Unigram_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66160\n",
      "72975\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for id in processed_corpus:\n",
    "    for token in processed_corpus[id]:\n",
    "        vocab.add(token)\n",
    "print(len(vocab))\n",
    "for id in test_corpus:\n",
    "    for token in test_corpus[id]:\n",
    "        vocab.add(token)\n",
    "print(len(vocab))\n",
    "V = len(vocab) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uni_sm_words = {}\n",
    "prob_uni_sm_words[\"<s>\"] = (unigram_counts[\"<s>\"] + 1) / (N_train + V)\n",
    "prob_uni_sm_words[\"</s>\"] = (unigram_counts[\"</s>\"] + 1) / (N_train + V)\n",
    "for token in test_tokens:\n",
    "        if token in unigram_counts:\n",
    "            prob_uni_sm_words[token] = (unigram_counts[token] + 1) / (N_train + V)\n",
    "        else:\n",
    "              prob_uni_sm_words[token] = 1 / (N_train + V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_sm = {}\n",
    "pp_sm = 0\n",
    "for id in test_corpus:\n",
    "    N = 2 + len(test_corpus[id])\n",
    "    temp = log(prob_uni_sm_words[\"<s>\"])\n",
    "    for token in test_corpus[id]:\n",
    "        temp += log(prob_uni_sm_words[token])\n",
    "    temp += log(prob_uni_sm_words[\"</s>\"])\n",
    "    temp=(-temp)/N\n",
    "    perplexity_sm[id] = exp(temp)\n",
    "    pp_sm += perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unigram_sm_pp = pp_sm/len(test_corpus)\n",
    "print(\"Perplexity of Unigram Model with Laplace Smoothing is: \", Unigram_sm_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = {}\n",
    "for id in processed_corpus:\n",
    "    tokens = processed_corpus[id]\n",
    "    size = len(tokens)\n",
    "    if((\"<s> \"+tokens[0]) not in bigram_counts):\n",
    "        bigram_counts[\"<s> \"+ tokens[0]] = 0\n",
    "    bigram_counts[\"<s> \"+tokens[0]] += 1\n",
    "    for i in range(0,size-1):\n",
    "        str = tokens[i] + \" \" + tokens[i+1]\n",
    "        if(str not in bigram_counts):\n",
    "            bigram_counts[str] = 0\n",
    "        bigram_counts[str] += 1\n",
    "    if ((tokens[size-1] + \" </s>\") not in bigram_counts):\n",
    "        bigram_counts[tokens[size-1] + \" </s>\"] = 0\n",
    "    bigram_counts[tokens[size-1] + \" </s>\"]+= 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_gram(processed_corpus, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_words = train_n_gram(processed_corpus,3,vocab=V,smoothing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp,avg_pp = test_n_gram(test_data=test_corpus,n=3,prob_words=prob_words,Vocabulary=V,smoothing=True,processed_corpus=processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4718.023443377587"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_bi_words = {}\n",
    "for id in test_corpus:\n",
    "    tokens = [\"<s>\"]\n",
    "    tokens += test_corpus[id]\n",
    "    tokens.append(\"</s>\")\n",
    "    size = len(tokens)\n",
    "    for i in range(0,size-1):\n",
    "        key = tokens[i]+ \" \"+ tokens[i+1]\n",
    "        if key in bigram_counts:\n",
    "            prob_bi_words[key] = bigram_counts[key] / unigram_counts[tokens[i]]\n",
    "        else:\n",
    "            prob_bi_words[key] = 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_perplexity = {}\n",
    "bi_pp = 0\n",
    "ep=1e-15\n",
    "for id in test_corpus:\n",
    "    N = 2 + len(test_corpus[id])\n",
    "    tokens = [\"<s>\"]\n",
    "    tokens += test_corpus[id]\n",
    "    tokens.append(\"</s>\")\n",
    "    size = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,size-1):\n",
    "        str = tokens[i] + \" \" + tokens[i+1]\n",
    "        if prob_bi_words[str]!=0:\n",
    "            temp += log(prob_bi_words[str])\n",
    "        else:\n",
    "            temp += log(prob_bi_words[str]+ep)\n",
    "    temp = (-temp)/N\n",
    "    bi_perplexity[id] = exp(temp)\n",
    "    bi_pp += bi_perplexity[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Bigram Model without smoothing is:  41282723511.56121\n"
     ]
    }
   ],
   "source": [
    "Bigram_pp = bi_pp/len(test_corpus)\n",
    "print(\"Perplexity of Bigram Model without smoothing is: \", Bigram_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_bi_sm_words = {}\n",
    "for key in bigram_counts:\n",
    "    w1,w2 = key.split(\" \")\n",
    "    if(key not in prob_bi_sm_words):\n",
    "        prob_bi_sm_words[key] = (bigram_counts[key] + 1) / (unigram_counts[w1] + V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_perplexity_sm = {}\n",
    "bi_pp_sm = 0\n",
    "for id in test_corpus:\n",
    "    N = 2 + len(test_corpus[id])\n",
    "    tokens = [\"<s>\"]\n",
    "    tokens += test_corpus[id]\n",
    "    tokens.append(\"</s>\")\n",
    "    size = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,size-1):\n",
    "        str = tokens[i] + \" \" + tokens[i+1]\n",
    "        if(str in prob_bi_sm_words):\n",
    "            temp += log(prob_bi_sm_words[str])\n",
    "        elif (tokens[i] in unigram_counts):\n",
    "            p = 1 / (unigram_counts[tokens[i]] + V)\n",
    "            temp += log(p)\n",
    "        else:\n",
    "            p = 1/V\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    bi_perplexity_sm[id] = exp(temp)\n",
    "    bi_pp_sm += bi_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bigram_sm_pp = bi_pp_sm/len(test_corpus)\n",
    "print(\"Perplexity of Bigram Model with smoothing is: \", Bigram_sm_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_counts = {}\n",
    "for id in processed_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\"]\n",
    "    tokens += processed_corpus[id] + [\"</s>\", \"</s>\"]\n",
    "    size = len(tokens)\n",
    "    for i in range(0,size-2):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2]\n",
    "        if(str not in trigram_counts):\n",
    "            trigram_counts[str] = 0\n",
    "        trigram_counts[str] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trigram_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tri_words = {}\n",
    "for key in trigram_counts:\n",
    "    w1,w2,w3 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2\n",
    "    if (prev in bigram_counts):\n",
    "        prob_tri_words[key] = trigram_counts[key] / bigram_counts[prev]\n",
    "    else:\n",
    "        prob_tri_words[key] = trigram_counts[key] / unigram_counts[w2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,k = train_n_gram(processed_corpus, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tri_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k == prob_tri_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_perplexity = {}\n",
    "tri_pp = 0\n",
    "ep=1e-15\n",
    "for id in test_corpus:\n",
    "    N = 4 + len(test_corpus[id])\n",
    "    tokens = [\"<s>\", \"<s>\"]\n",
    "    tokens += test_corpus[id] + [\"</s>\", \"</s>\"]\n",
    "    size = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,size-2):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2]\n",
    "        if(str in prob_tri_words):\n",
    "            temp += log(prob_tri_words[str])\n",
    "        else:\n",
    "            temp +=log(ep)\n",
    "    temp = (-temp)/N\n",
    "    tri_perplexity[id] = exp(temp)\n",
    "    tri_pp += tri_perplexity[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trigram_pp = tri_pp/len(test_corpus)\n",
    "print(\"Perplexity of Trigram Model without smoothing is: \", Trigram_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigram Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tri_sm_words = {}\n",
    "for key in trigram_counts:\n",
    "    w1,w2,w3 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2\n",
    "    if (prev in bigram_counts):\n",
    "        prob_tri_sm_words[key] = (trigram_counts[key] + 1) / (bigram_counts[prev] + V)\n",
    "    else:\n",
    "        prob_tri_sm_words[key] = (trigram_counts[key] + 1) / (unigram_counts[w2] + V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_perplexity_sm = {}\n",
    "tri_pp_sm = 0\n",
    "for id in test_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\"]\n",
    "    tokens += test_corpus[id] + [\"</s>\", \"</s>\"]\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-2):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2]\n",
    "        if(str in prob_tri_sm_words):\n",
    "            temp += log(prob_tri_sm_words[str])\n",
    "        else:\n",
    "            prev = tokens[i] + \" \" + tokens[i+1]\n",
    "            if (prev in bigram_counts):\n",
    "                p = 1 /(bigram_counts[prev] + V)\n",
    "            elif (tokens[i+1]==\"<s>\"):\n",
    "                p = 1 /(unigram_counts[tokens[i+1]] + V)\n",
    "            else:\n",
    "                p = 1/V\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    tri_perplexity_sm[id] = exp(temp)\n",
    "    tri_pp_sm += tri_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Trigram Model is:  4864.238170902633\n"
     ]
    }
   ],
   "source": [
    "Trigram_sm_pp = tri_pp_sm/len(test_corpus)\n",
    "print(\"Perplexity of Trigram Model is: \", Trigram_sm_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadgram_counts = {}\n",
    "for id in processed_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\", \"<s>\"]\n",
    "    tokens += processed_corpus[id] + [\"</s>\", \"</s>\", \"</s>\"]\n",
    "    size = len(tokens)\n",
    "    for i in range(0,size-3):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2] + \" \" + tokens[i+3]\n",
    "        if(str not in quadgram_counts):\n",
    "            quadgram_counts[str] = 0\n",
    "        quadgram_counts[str] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(quadgram_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_quad_words = {}\n",
    "for key in quadgram_counts:\n",
    "    w1,w2,w3,w4 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2 + \" \" + w3\n",
    "    if (prev in trigram_counts):\n",
    "        prob_quad_words[key] = quadgram_counts[key] / trigram_counts[prev]\n",
    "    else:\n",
    "        prob_quad_words[key] = quadgram_counts[key] / unigram_counts[w3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_perplexity = {}\n",
    "quad_pp = 0\n",
    "ep=1e-15\n",
    "for id in test_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\",\"<s>\"]\n",
    "    tokens += test_corpus[id] + [\"</s>\", \"</s>\", \"</s>\"]\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-3):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2] + \" \" + tokens[i+3]\n",
    "        if(str in prob_quad_words):\n",
    "            temp += log(prob_quad_words[str])\n",
    "        else:\n",
    "            temp +=log(ep)\n",
    "    temp = (-temp)/N\n",
    "    quad_perplexity[id] = exp(temp)\n",
    "    quad_pp += quad_perplexity[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quadgram_pp = quad_pp/len(test_corpus)\n",
    "print(\"Perplexity of Quadgram Model without smoothing is: \", Quadgram_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadgram Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_quad_sm_words = {}\n",
    "for key in quadgram_counts:\n",
    "    w1,w2,w3,w4 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2 + \" \" + w3\n",
    "    if (prev in trigram_counts):\n",
    "        prob_quad_sm_words[key] = (quadgram_counts[key] + 1) / (trigram_counts[prev] + V)\n",
    "    else:\n",
    "        prob_quad_sm_words[key] = (quadgram_counts[key] + 1) / (unigram_counts[w3] + V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_perplexity_sm = {}\n",
    "quad_pp_sm = 0\n",
    "\n",
    "for id in test_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\", \"<s>\"]\n",
    "    tokens += test_corpus[id] + [\"</s>\", \"</s>\", \"</s>\"]\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-3):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2] + \" \" + tokens[i+3]\n",
    "        if(str in prob_quad_sm_words):\n",
    "            temp += log(prob_quad_sm_words[str])\n",
    "        else:\n",
    "            prev = tokens[i] + \" \" + tokens[i+1] + \" \" +tokens[i+2]\n",
    "            if (prev in trigram_counts):\n",
    "                p = 1 /(trigram_counts[prev] + V)\n",
    "            elif ((tokens[i+1]+\" \" + tokens[i+2]) in bigram_counts):\n",
    "                p = 1 /(bigram_counts[(tokens[i+1]+\" \" + tokens[i+2])] + V)\n",
    "            elif (tokens[i+2] in unigram_counts):\n",
    "                p = 1/(unigram_counts[tokens[i+2]] + V)\n",
    "            else:\n",
    "                p = 1/V\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    quad_perplexity_sm[id] = exp(temp)\n",
    "    quad_pp_sm += quad_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quadgram_sm_pp = quad_pp_sm/len(test_corpus)\n",
    "print(\"Perplexity of Quadgram Model with smoothing is: \", Quadgram_sm_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram On Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_train= len(unigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prob_uni_sm_words = {}\n",
    "for token in unigram_counts:\n",
    "    train_prob_uni_sm_words[token] = (unigram_counts[token]) / (N_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0\n",
    "for token in unigram_counts:\n",
    "    p+=log(train_prob_uni_sm_words[token])\n",
    "p=(-p)/len(unigram_counts)\n",
    "p=exp(p)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uni_perplexity_sm = {}\n",
    "train_uni_pp_sm = 0\n",
    "for id in processed_corpus:\n",
    "    N = 2 + len(processed_corpus[id])\n",
    "    temp = log(train_prob_uni_sm_words[\"<s>\"])\n",
    "    for token in processed_corpus[id]:\n",
    "        temp += log(train_prob_uni_sm_words[token])\n",
    "    temp += log(train_prob_uni_sm_words[\"</s>\"])\n",
    "    temp=(-temp)/N\n",
    "    train_uni_perplexity_sm[id] = exp(temp)\n",
    "    train_uni_pp_sm += train_uni_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Unigram_perplexity = train_uni_pp_sm/len(processed_corpus)\n",
    "print(\"Perplexity of Unigram Model on train data: \", train_Unigram_perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prob_bi_sm_words = {}\n",
    "for key in bigram_counts:\n",
    "    w1,w2 = key.split(\" \")\n",
    "    train_prob_bi_sm_words[key] = (bigram_counts[key]) / (unigram_counts[w1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bi_perplexity_sm = {}\n",
    "train_bi_pp_sm = 0\n",
    "for id in processed_corpus:\n",
    "    tokens = [\"<s>\"]\n",
    "    tokens += processed_corpus[id]\n",
    "    tokens.append(\"</s>\")\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-1):\n",
    "        str = tokens[i] + \" \" + tokens[i+1]\n",
    "        if(str in train_prob_bi_sm_words):\n",
    "            temp += log(train_prob_bi_sm_words[str])\n",
    "        elif (tokens[i] in unigram_counts):\n",
    "            print(\"bhahhhhh\")\n",
    "            p = 1 / (unigram_counts[tokens[i]] + V_train)\n",
    "            temp += log(p)\n",
    "        else:\n",
    "            print(\"booooooo\")\n",
    "            p = 1/V_train\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    train_bi_perplexity_sm[id] = exp(temp)\n",
    "    train_bi_pp_sm += train_bi_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Bigram_perplexity = train_bi_pp_sm/len(processed_corpus)\n",
    "print(\"Perplexity of Bigram Model on train data: \", train_Bigram_perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigram on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prob_tri_sm_words = {}\n",
    "for key in trigram_counts:\n",
    "    w1,w2,w3 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2\n",
    "    if (prev in bigram_counts):\n",
    "        train_prob_tri_sm_words[key] = (trigram_counts[key]) / (bigram_counts[prev])\n",
    "    else:\n",
    "        train_prob_tri_sm_words[key] = (trigram_counts[key]) / (unigram_counts[w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tri_perplexity_sm = {}\n",
    "train_tri_pp_sm = 0\n",
    "for id in processed_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\"]\n",
    "    tokens += processed_corpus[id] + [\"</s>\", \"</s>\"]\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-2):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2]\n",
    "        if(str in train_prob_tri_sm_words):\n",
    "            temp += log(train_prob_tri_sm_words[str])\n",
    "        else:\n",
    "            prev = tokens[i] + \" \" + tokens[i+1]\n",
    "            if (prev in bigram_counts):\n",
    "                print(\"A\")\n",
    "                p = 1 /(bigram_counts[prev] + V_train)\n",
    "            elif (tokens[i+1] in unigram_counts):\n",
    "                print(\"B\")\n",
    "                p = 1 /(unigram_counts[tokens[i+1]] + V_train)\n",
    "            else:\n",
    "                print(\"C\")\n",
    "                p = 1/V_train\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    train_tri_perplexity_sm[id] = exp(temp)\n",
    "    train_tri_pp_sm += train_tri_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tri_pp_sm/len(processed_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadgram on train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_quad_sm_words = {}\n",
    "for key in quadgram_counts:\n",
    "    w1,w2,w3,w4 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2 + \" \" + w3\n",
    "    if (prev in trigram_counts):\n",
    "        prob_quad_sm_words[key] = (quadgram_counts[key]) / (trigram_counts[prev])\n",
    "    else:\n",
    "        prob_quad_sm_words[key] = (quadgram_counts[key]) / (unigram_counts[w3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_perplexity_sm = {}\n",
    "quad_pp_sm = 0\n",
    "\n",
    "for id in processed_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\", \"<s>\"]\n",
    "    tokens += processed_corpus[id] + [\"</s>\", \"</s>\", \"</s>\"]\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-3):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2] + \" \" + tokens[i+3]\n",
    "        if(str in prob_quad_sm_words):\n",
    "            temp += log(prob_quad_sm_words[str])\n",
    "    temp = (-temp)/N\n",
    "    quad_perplexity_sm[id] = exp(temp)\n",
    "    quad_pp_sm += quad_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quadgram_sm_pp = quad_pp_sm/len(processed_corpus)\n",
    "print(\"Perplexity of Quadgram Model with smoothing is: \", Quadgram_sm_pp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
