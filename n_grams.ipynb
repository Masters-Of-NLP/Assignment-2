{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, exp\n",
    "import pandas as pd\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seriously ask any woman they will tell you thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in us of taxpayers paid tax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haha russia go boom splat india go ahhh plop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can t say i m surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they use the religious label for social contro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  seriously ask any woman they will tell you thi...\n",
       "1                        in us of taxpayers paid tax\n",
       "2       haha russia go boom splat india go ahhh plop\n",
       "3                            can t say i m surprised\n",
       "4  they use the religious label for social contro..."
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"Dataset/Training/train_data.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {df.columns[0]:\"Value\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_corpus = {} \n",
    "sentence_id = 0\n",
    "for sentence in df['Value']:\n",
    "    tokenized_sentence = []\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = (token for token in tokens if token.isalpha())\n",
    "    tokenized_sentence += tokens\n",
    "    processed_corpus[sentence_id] = tokenized_sentence\n",
    "    sentence_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seriously', 'ask', 'any', 'woman', 'they', 'will', 'tell', 'you', 'this', 'is', 'all', 'very', 'common']\n"
     ]
    }
   ],
   "source": [
    "print(processed_corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_counts = {}\n",
    "unigram_counts[\"<s>\"] = 0\n",
    "unigram_counts[\"</s>\"] = 0\n",
    "for id in processed_corpus:\n",
    "    for token in processed_corpus[id]:\n",
    "        if token not in unigram_counts:\n",
    "            unigram_counts[token] = 0\n",
    "        unigram_counts[token] += 1\n",
    "    unigram_counts[\"<s>\"] += 1\n",
    "    unigram_counts[\"</s>\"] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66112"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actually that s a really amazing idea mashaallah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the chinese fella was trying to take him on li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i honestly think international troops will be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marry man s best friend if the man isn t good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if climate change will submerge all those plac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0   actually that s a really amazing idea mashaallah\n",
       "1  the chinese fella was trying to take him on li...\n",
       "2  i honestly think international troops will be ...\n",
       "3  marry man s best friend if the man isn t good ...\n",
       "4  if climate change will submerge all those plac..."
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"Dataset/Testing/test_data.csv\"\n",
    "df_test = pd.read_csv(filepath)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actually that s a really amazing idea mashaallah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the chinese fella was trying to take him on li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i honestly think international troops will be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marry man s best friend if the man isn t good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if climate change will submerge all those plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65745</th>\n",
       "      <td>because the sky is high and so am i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65746</th>\n",
       "      <td>view link info feedback for savevideo donate d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65747</th>\n",
       "      <td>fortunately the court did the right thing desp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65748</th>\n",
       "      <td>yeah they kept improving man it was a nervous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65749</th>\n",
       "      <td>but china has rules in place that essentially ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65750 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Value\n",
       "0       actually that s a really amazing idea mashaallah\n",
       "1      the chinese fella was trying to take him on li...\n",
       "2      i honestly think international troops will be ...\n",
       "3      marry man s best friend if the man isn t good ...\n",
       "4      if climate change will submerge all those plac...\n",
       "...                                                  ...\n",
       "65745                because the sky is high and so am i\n",
       "65746  view link info feedback for savevideo donate d...\n",
       "65747  fortunately the court did the right thing desp...\n",
       "65748  yeah they kept improving man it was a nervous ...\n",
       "65749  but china has rules in place that essentially ...\n",
       "\n",
       "[65750 rows x 1 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.rename(columns = {df_test.columns[0]:\"Value\"},inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = {}\n",
    "test_tokens = set()\n",
    "sentence_id = 0\n",
    "num_test_words = 0\n",
    "for sentence in df_test['Value']:\n",
    "    tokenized_sentence = []\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = (token for token in tokens if token.isalpha())\n",
    "    tokenized_sentence += tokens\n",
    "    test_corpus[sentence_id] = tokenized_sentence\n",
    "    num_test_words += 2 + len(tokenized_sentence)\n",
    "    for token in tokenized_sentence:\n",
    "        test_tokens.add(token)\n",
    "    sentence_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 0\n",
    "for token in unigram_counts:\n",
    "    N_train += unigram_counts[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35292"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating perplexity\n",
    "\n",
    "prob_uni_words = {}\n",
    "prob_uni_words[\"<s>\"] = unigram_counts[\"<s>\"] / N_train\n",
    "prob_uni_words[\"</s>\"] = unigram_counts[\"</s>\"] / N_train\n",
    "for token in test_tokens:\n",
    "        if token in unigram_counts:\n",
    "            prob_uni_words[token] = unigram_counts[token]/N_train\n",
    "        else:\n",
    "            prob_uni_words[token] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6865"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_vocab = 0\n",
    "for i in prob_uni_words:\n",
    "    if(prob_uni_words[i]==0):\n",
    "        out_of_vocab+=1\n",
    "out_of_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = {}\n",
    "ep=1e-15\n",
    "pp = 0\n",
    "for id in test_corpus:\n",
    "    N = 2 + len(test_corpus[id])\n",
    "    temp = log(prob_uni_words[\"<s>\"])\n",
    "    for token in test_corpus[id]:\n",
    "        if(prob_uni_words[token]==0):\n",
    "            temp += log(prob_uni_words[token]+ep)\n",
    "        else:\n",
    "            temp += log(prob_uni_words[token])\n",
    "    temp += log(prob_uni_words[\"</s>\"])\n",
    "    temp = (-temp)/N\n",
    "    perplexity[id] = exp(temp)\n",
    "    pp += perplexity[id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Unigram Model without smoothing is:  255029160.07513976\n"
     ]
    }
   ],
   "source": [
    "Unigram_pp = pp/len(test_corpus)\n",
    "print(\"Perplexity of Unigram Model without smoothing is: \", Unigram_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66110\n",
      "72975\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for id in processed_corpus:\n",
    "    for token in processed_corpus[id]:\n",
    "        vocab.add(token)\n",
    "print(len(vocab))\n",
    "for id in test_corpus:\n",
    "    for token in test_corpus[id]:\n",
    "        vocab.add(token)\n",
    "print(len(vocab))\n",
    "V = len(vocab) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uni_sm_words = {}\n",
    "prob_uni_sm_words[\"<s>\"] = (unigram_counts[\"<s>\"] + 1) / (N_train + V)\n",
    "prob_uni_sm_words[\"</s>\"] = (unigram_counts[\"</s>\"] + 1) / (N_train + V)\n",
    "for token in test_tokens:\n",
    "        if token in unigram_counts:\n",
    "            prob_uni_sm_words[token] = (unigram_counts[token] + 1) / (N_train + V)\n",
    "        else:\n",
    "              prob_uni_sm_words[token] = 1 / (N_train + V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_sm = {}\n",
    "pp_sm = 0\n",
    "for id in test_corpus:\n",
    "    N = 2 + len(test_corpus[id])\n",
    "    temp = log(prob_uni_sm_words[\"<s>\"])\n",
    "    for token in test_corpus[id]:\n",
    "        temp += log(prob_uni_sm_words[token])\n",
    "    temp += log(prob_uni_sm_words[\"</s>\"])\n",
    "    temp=(-temp)/N\n",
    "    perplexity_sm[id] = exp(temp)\n",
    "    pp_sm += perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Unigram Model with Laplace Smoothing is:  1277.93160029543\n"
     ]
    }
   ],
   "source": [
    "Unigram_sm_pp = pp_sm/len(test_corpus)\n",
    "print(\"Perplexity of Unigram Model with Laplace Smoothing is: \", Unigram_sm_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = {}\n",
    "for id in processed_corpus:\n",
    "    tokens = processed_corpus[id]\n",
    "    size = len(tokens)\n",
    "    if((\"<s> \"+tokens[0]) not in bigram_counts):\n",
    "        bigram_counts[\"<s> \"+ tokens[0]] = 0\n",
    "    bigram_counts[\"<s> \"+tokens[0]] += 1\n",
    "    for i in range(0,size-1):\n",
    "        str = tokens[i] + \" \" + tokens[i+1]\n",
    "        if(str not in bigram_counts):\n",
    "            bigram_counts[str] = 0\n",
    "        bigram_counts[str] += 1\n",
    "    if ((tokens[size-1] + \" </s>\") not in bigram_counts):\n",
    "        bigram_counts[tokens[size-1] + \" </s>\"] = 0\n",
    "    bigram_counts[tokens[size-1] + \" </s>\"]+= 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "871874"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_bi_words = {}\n",
    "for id in test_corpus:\n",
    "    tokens = [\"<s>\"]\n",
    "    tokens += test_corpus[id]\n",
    "    tokens.append(\"</s>\")\n",
    "    size = len(tokens)\n",
    "    for i in range(0,size-1):\n",
    "        key = tokens[i]+ \" \"+ tokens[i+1]\n",
    "        if key in bigram_counts:\n",
    "            prob_bi_words[key] = bigram_counts[key] / unigram_counts[tokens[i]]\n",
    "        else:\n",
    "            prob_bi_words[key] = 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_perplexity = {}\n",
    "bi_pp = 0\n",
    "ep=1e-15\n",
    "for id in test_corpus:\n",
    "    N = 2 + len(test_corpus[id])\n",
    "    tokens = [\"<s>\"]\n",
    "    tokens += test_corpus[id]\n",
    "    tokens.append(\"</s>\")\n",
    "    size = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,size-1):\n",
    "        str = tokens[i] + \" \" + tokens[i+1]\n",
    "        if prob_bi_words[str]!=0:\n",
    "            temp += log(prob_bi_words[str])\n",
    "        else:\n",
    "            temp += log(prob_bi_words[str]+ep)\n",
    "    temp = (-temp)/N\n",
    "    bi_perplexity[id] = exp(temp)\n",
    "    bi_pp += bi_perplexity[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Bigram Model without smoothing is:  31069869118.23472\n"
     ]
    }
   ],
   "source": [
    "Bigram_pp = bi_pp/len(test_corpus)\n",
    "print(\"Perplexity of Bigram Model without smoothing is: \", Bigram_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_bi_sm_words = {}\n",
    "for key in bigram_counts:\n",
    "    w1,w2 = key.split(\" \")\n",
    "    if(key not in prob_bi_sm_words):\n",
    "        prob_bi_sm_words[key] = (bigram_counts[key] + 1) / (unigram_counts[w1] + V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_perplexity_sm = {}\n",
    "bi_pp_sm = 0\n",
    "for id in test_corpus:\n",
    "    N = 2 + len(test_corpus[id])\n",
    "    tokens = [\"<s>\"]\n",
    "    tokens += test_corpus[id]\n",
    "    tokens.append(\"</s>\")\n",
    "    size = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,size-1):\n",
    "        str = tokens[i] + \" \" + tokens[i+1]\n",
    "        if(str in prob_bi_sm_words):\n",
    "            temp += log(prob_bi_sm_words[str])\n",
    "        elif (tokens[i] in unigram_counts):\n",
    "            p = 1 / (unigram_counts[tokens[i]] + V)\n",
    "            temp += log(p)\n",
    "        else:\n",
    "            p = 1/V\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    bi_perplexity_sm[id] = exp(temp)\n",
    "    bi_pp_sm += bi_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Bigram Model with smoothing is:  1985.1815331914747\n"
     ]
    }
   ],
   "source": [
    "Bigram_sm_pp = bi_pp_sm/len(test_corpus)\n",
    "print(\"Perplexity of Bigram Model with smoothing is: \", Bigram_sm_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_counts = {}\n",
    "for id in processed_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\"]\n",
    "    tokens += processed_corpus[id] + [\"</s>\", \"</s>\"]\n",
    "    size = len(tokens)\n",
    "    for i in range(0,size-2):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2]\n",
    "        if(str not in trigram_counts):\n",
    "            trigram_counts[str] = 0\n",
    "        trigram_counts[str] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2136765\n"
     ]
    }
   ],
   "source": [
    "print(len(trigram_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tri_words = {}\n",
    "for key in trigram_counts:\n",
    "    w1,w2,w3 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2\n",
    "    if (prev in bigram_counts):\n",
    "        prob_tri_words[key] = trigram_counts[key] / bigram_counts[prev]\n",
    "    else:\n",
    "        prob_tri_words[key] = trigram_counts[key] / unigram_counts[w2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_perplexity = {}\n",
    "tri_pp = 0\n",
    "ep=1e-15\n",
    "for id in test_corpus:\n",
    "    N = 4 + len(test_corpus[id])\n",
    "    tokens = [\"<s>\", \"<s>\"]\n",
    "    tokens += test_corpus[id] + [\"</s>\", \"</s>\"]\n",
    "    size = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,size-2):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2]\n",
    "        if(str in prob_tri_words):\n",
    "            temp += log(prob_tri_words[str])\n",
    "        else:\n",
    "            temp +=log(ep)\n",
    "    temp = (-temp)/N\n",
    "    tri_perplexity[id] = exp(temp)\n",
    "    tri_pp += tri_perplexity[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Trigram Model without smoothing is:  69139995101.5171\n"
     ]
    }
   ],
   "source": [
    "Trigram_pp = tri_pp/len(test_corpus)\n",
    "print(\"Perplexity of Trigram Model without smoothing is: \", Trigram_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigram Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tri_sm_words = {}\n",
    "for key in trigram_counts:\n",
    "    w1,w2,w3 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2\n",
    "    if (prev in bigram_counts):\n",
    "        prob_tri_sm_words[key] = (trigram_counts[key] + 1) / (bigram_counts[prev] + V)\n",
    "    else:\n",
    "        prob_tri_sm_words[key] = (trigram_counts[key] + 1) / (unigram_counts[w2] + V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_perplexity_sm = {}\n",
    "tri_pp_sm = 0\n",
    "for id in test_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\"]\n",
    "    tokens += test_corpus[id] + [\"</s>\", \"</s>\"]\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-2):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2]\n",
    "        if(str in prob_tri_sm_words):\n",
    "            temp += log(prob_tri_sm_words[str])\n",
    "        else:\n",
    "            prev = tokens[i] + \" \" + tokens[i+1]\n",
    "            if (prev in bigram_counts):\n",
    "                p = 1 /(bigram_counts[prev] + V)\n",
    "            elif (tokens[i+1] in unigram_counts):\n",
    "                p = 1 /(unigram_counts[tokens[i+1]] + V)\n",
    "            else:\n",
    "                p = 1/V\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    tri_perplexity_sm[id] = exp(temp)\n",
    "    tri_pp_sm += tri_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Trigram Model is:  4955.669477563053\n"
     ]
    }
   ],
   "source": [
    "Trigram_sm_pp = tri_pp_sm/len(test_corpus)\n",
    "print(\"Perplexity of Trigram Model is: \", Trigram_sm_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadgram_counts = {}\n",
    "for id in processed_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\", \"<s>\"]\n",
    "    tokens += processed_corpus[id] + [\"</s>\", \"</s>\", \"</s>\"]\n",
    "    size = len(tokens)\n",
    "    for i in range(0,size-3):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2] + \" \" + tokens[i+3]\n",
    "        if(str not in quadgram_counts):\n",
    "            quadgram_counts[str] = 0\n",
    "        quadgram_counts[str] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2910767\n"
     ]
    }
   ],
   "source": [
    "print(len(quadgram_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_quad_words = {}\n",
    "for key in quadgram_counts:\n",
    "    w1,w2,w3,w4 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2 + \" \" + w3\n",
    "    if (prev in trigram_counts):\n",
    "        prob_quad_words[key] = quadgram_counts[key] / trigram_counts[prev]\n",
    "    else:\n",
    "        prob_quad_words[key] = quadgram_counts[key] / unigram_counts[w3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_perplexity = {}\n",
    "quad_pp = 0\n",
    "ep=1e-15\n",
    "for id in test_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\",\"<s>\"]\n",
    "    tokens += test_corpus[id] + [\"</s>\", \"</s>\", \"</s>\"]\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-3):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2] + \" \" + tokens[i+3]\n",
    "        if(str in prob_quad_words):\n",
    "            temp += log(prob_quad_words[str])\n",
    "        else:\n",
    "            temp +=log(ep)\n",
    "    temp = (-temp)/N\n",
    "    quad_perplexity[id] = exp(temp)\n",
    "    quad_pp += quad_perplexity[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Quadgram Model without smoothing is:  292224555035.2341\n"
     ]
    }
   ],
   "source": [
    "Quadgram_pp = quad_pp/len(test_corpus)\n",
    "print(\"Perplexity of Quadgram Model without smoothing is: \", Quadgram_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadgram Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_quad_sm_words = {}\n",
    "for key in quadgram_counts:\n",
    "    w1,w2,w3,w4 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2 + \" \" + w3\n",
    "    if (prev in trigram_counts):\n",
    "        prob_quad_sm_words[key] = (quadgram_counts[key] + 1) / (trigram_counts[prev] + V)\n",
    "    else:\n",
    "        prob_quad_sm_words[key] = (quadgram_counts[key] + 1) / (unigram_counts[w3] + V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_perplexity_sm = {}\n",
    "quad_pp_sm = 0\n",
    "\n",
    "for id in test_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\", \"<s>\"]\n",
    "    tokens += test_corpus[id] + [\"</s>\", \"</s>\", \"</s>\"]\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-3):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2] + \" \" + tokens[i+3]\n",
    "        if(str in prob_quad_sm_words):\n",
    "            temp += log(prob_quad_sm_words[str])\n",
    "        else:\n",
    "            prev = tokens[i] + \" \" + tokens[i+1] + \" \" +tokens[i+2]\n",
    "            if (prev in trigram_counts):\n",
    "                p = 1 /(trigram_counts[prev] + V)\n",
    "            elif ((tokens[i+1]+\" \" + tokens[i+2]) in bigram_counts):\n",
    "                p = 1 /(bigram_counts[(tokens[i+1]+\" \" + tokens[i+2])] + V)\n",
    "            elif (tokens[i+2] in unigram_counts):\n",
    "                p = 1/(unigram_counts[tokens[i+2]] + V)\n",
    "            else:\n",
    "                p = 1/V\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    quad_perplexity_sm[id] = exp(temp)\n",
    "    quad_pp_sm += quad_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Quadgram Model with smoothing is:  5563.028169800954\n"
     ]
    }
   ],
   "source": [
    "Quadgram_sm_pp = quad_pp_sm/len(test_corpus)\n",
    "print(\"Perplexity of Quadgram Model with smoothing is: \", Quadgram_sm_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram On Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_train=66110+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prob_uni_sm_words = {}\n",
    "for token in unigram_counts:\n",
    "    train_prob_uni_sm_words[token] = (unigram_counts[token] + 1) / (N_train + V_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855095.4860045433"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=0\n",
    "for token in unigram_counts:\n",
    "    p+=log(train_prob_uni_sm_words[token])\n",
    "p=(-p)/len(unigram_counts)\n",
    "p=exp(p)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uni_perplexity_sm = {}\n",
    "train_uni_pp_sm = 0\n",
    "for id in processed_corpus:\n",
    "    N = 2 + len(processed_corpus[id])\n",
    "    temp = log(train_prob_uni_sm_words[\"<s>\"])\n",
    "    for token in processed_corpus[id]:\n",
    "        temp += log(train_prob_uni_sm_words[token])\n",
    "    temp += log(train_prob_uni_sm_words[\"</s>\"])\n",
    "    temp=(-temp)/N\n",
    "    train_uni_perplexity_sm[id] = exp(temp)\n",
    "    train_uni_pp_sm += train_uni_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Unigram Model on train data:  1165.658690125828\n"
     ]
    }
   ],
   "source": [
    "train_Unigram_perplexity = train_uni_pp_sm/len(processed_corpus)\n",
    "print(\"Perplexity of Unigram Model on train data: \", train_Unigram_perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prob_bi_sm_words = {}\n",
    "for key in bigram_counts:\n",
    "    w1,w2 = key.split(\" \")\n",
    "    train_prob_bi_sm_words[key] = (bigram_counts[key] + 1) / (unigram_counts[w1] + V_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bi_perplexity_sm = {}\n",
    "train_bi_pp_sm = 0\n",
    "for id in processed_corpus:\n",
    "    tokens = [\"<s>\"]\n",
    "    tokens += processed_corpus[id]\n",
    "    tokens.append(\"</s>\")\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-1):\n",
    "        str = tokens[i] + \" \" + tokens[i+1]\n",
    "        if(str in train_prob_bi_sm_words):\n",
    "            temp += log(train_prob_bi_sm_words[str])\n",
    "        elif (tokens[i] in unigram_counts):\n",
    "            print(\"bhahhhhh\")\n",
    "            p = 1 / (unigram_counts[tokens[i]] + V_train)\n",
    "            temp += log(p)\n",
    "        else:\n",
    "            print(\"booooooo\")\n",
    "            p = 1/V_train\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    train_bi_perplexity_sm[id] = exp(temp)\n",
    "    train_bi_pp_sm += train_bi_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Bigram Model on train data:  1424.1571861376087\n"
     ]
    }
   ],
   "source": [
    "train_Bigram_perplexity = train_bi_pp_sm/len(processed_corpus)\n",
    "print(\"Perplexity of Bigram Model on train data: \", train_Bigram_perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigram on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prob_tri_sm_words = {}\n",
    "for key in trigram_counts:\n",
    "    w1,w2,w3 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2\n",
    "    if (prev in bigram_counts):\n",
    "        train_prob_tri_sm_words[key] = (trigram_counts[key] + 1) / (bigram_counts[prev] + V_train)\n",
    "    else:\n",
    "        train_prob_tri_sm_words[key] = (trigram_counts[key] + 1) / (unigram_counts[w2] + V_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tri_perplexity_sm = {}\n",
    "train_tri_pp_sm = 0\n",
    "for id in processed_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\"]\n",
    "    tokens += processed_corpus[id] + [\"</s>\", \"</s>\"]\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-2):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2]\n",
    "        if(str in train_prob_tri_sm_words):\n",
    "            temp += log(train_prob_tri_sm_words[str])\n",
    "        else:\n",
    "            prev = tokens[i] + \" \" + tokens[i+1]\n",
    "            if (prev in bigram_counts):\n",
    "                print(\"A\")\n",
    "                p = 1 /(bigram_counts[prev] + V_train)\n",
    "            elif (tokens[i+1] in unigram_counts):\n",
    "                print(\"B\")\n",
    "                p = 1 /(unigram_counts[tokens[i+1]] + V_train)\n",
    "            else:\n",
    "                print(\"C\")\n",
    "                p = 1/V_train\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    train_tri_perplexity_sm[id] = exp(temp)\n",
    "    train_tri_pp_sm += train_tri_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3017.846540326872"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tri_pp_sm/len(processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
