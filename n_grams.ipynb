{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from n_grams import *\n",
    "from math import log, exp\n",
    "import pandas as pd\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seriously ask any woman they will tell you thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in us of taxpayers paid tax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haha russia go boom splat india go ahhh plop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can t say i m surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they use the religious label for social contro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  seriously ask any woman they will tell you thi...\n",
       "1                        in us of taxpayers paid tax\n",
       "2       haha russia go boom splat india go ahhh plop\n",
       "3                            can t say i m surprised\n",
       "4  they use the religious label for social contro..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"Dataset/Training/train_data.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {df.columns[0]:\"Value\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_corpus = {} \n",
    "sentence_id = 0\n",
    "for sentence in df['Value']:\n",
    "    tokenized_sentence = []\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = (token for token in tokens if token.isalpha())\n",
    "    tokenized_sentence += tokens\n",
    "    processed_corpus[sentence_id] = tokenized_sentence\n",
    "    sentence_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seriously', 'ask', 'any', 'woman', 'they', 'will', 'tell', 'you', 'this', 'is', 'all', 'very', 'common']\n"
     ]
    }
   ],
   "source": [
    "print(processed_corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_counts = {}\n",
    "unigram_counts[\"<s>\"] = 0\n",
    "unigram_counts[\"</s>\"] = 0\n",
    "for id in processed_corpus:\n",
    "    for token in processed_corpus[id]:\n",
    "        if token not in unigram_counts:\n",
    "            unigram_counts[token] = 0\n",
    "        unigram_counts[token] += 1\n",
    "    unigram_counts[\"<s>\"] += 1\n",
    "    unigram_counts[\"</s>\"] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66112"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actually that s a really amazing idea mashaallah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the chinese fella was trying to take him on li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i honestly think international troops will be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marry man s best friend if the man isn t good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if climate change will submerge all those plac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0   actually that s a really amazing idea mashaallah\n",
       "1  the chinese fella was trying to take him on li...\n",
       "2  i honestly think international troops will be ...\n",
       "3  marry man s best friend if the man isn t good ...\n",
       "4  if climate change will submerge all those plac..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"Dataset/Testing/test_data.csv\"\n",
    "df_test = pd.read_csv(filepath)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actually that s a really amazing idea mashaallah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the chinese fella was trying to take him on li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i honestly think international troops will be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marry man s best friend if the man isn t good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if climate change will submerge all those plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65745</th>\n",
       "      <td>because the sky is high and so am i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65746</th>\n",
       "      <td>view link info feedback for savevideo donate d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65747</th>\n",
       "      <td>fortunately the court did the right thing desp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65748</th>\n",
       "      <td>yeah they kept improving man it was a nervous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65749</th>\n",
       "      <td>but china has rules in place that essentially ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65750 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Value\n",
       "0       actually that s a really amazing idea mashaallah\n",
       "1      the chinese fella was trying to take him on li...\n",
       "2      i honestly think international troops will be ...\n",
       "3      marry man s best friend if the man isn t good ...\n",
       "4      if climate change will submerge all those plac...\n",
       "...                                                  ...\n",
       "65745                because the sky is high and so am i\n",
       "65746  view link info feedback for savevideo donate d...\n",
       "65747  fortunately the court did the right thing desp...\n",
       "65748  yeah they kept improving man it was a nervous ...\n",
       "65749  but china has rules in place that essentially ...\n",
       "\n",
       "[65750 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.rename(columns = {df_test.columns[0]:\"Value\"},inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = {}\n",
    "test_tokens = set()\n",
    "sentence_id = 0\n",
    "num_test_words = 0\n",
    "for sentence in df_test['Value']:\n",
    "    tokenized_sentence = []\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = (token for token in tokens if token.isalpha())\n",
    "    tokenized_sentence += tokens\n",
    "    test_corpus[sentence_id] = tokenized_sentence\n",
    "    num_test_words += 2 + len(tokenized_sentence)\n",
    "    for token in tokenized_sentence:\n",
    "        test_tokens.add(token)\n",
    "    sentence_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 0\n",
    "for token in unigram_counts:\n",
    "    N_train += unigram_counts[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35292"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating perplexity\n",
    "\n",
    "prob_uni_words = {}\n",
    "prob_uni_words[\"<s>\"] = unigram_counts[\"<s>\"] / N_train\n",
    "prob_uni_words[\"</s>\"] = unigram_counts[\"</s>\"] / N_train\n",
    "for token in test_tokens:\n",
    "        if token in unigram_counts:\n",
    "            prob_uni_words[token] = unigram_counts[token]/N_train\n",
    "        else:\n",
    "            prob_uni_words[token] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6865"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_vocab = 0\n",
    "for i in prob_uni_words:\n",
    "    if(prob_uni_words[i]==0):\n",
    "        out_of_vocab+=1\n",
    "out_of_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = {}\n",
    "ep=1e-15\n",
    "pp = 0\n",
    "# We are neglecting the words that does not appear in the train data\n",
    "for id in test_corpus:\n",
    "    N = 2 + len(test_corpus[id])\n",
    "    temp = log(prob_uni_words[\"<s>\"])\n",
    "    for token in test_corpus[id]:\n",
    "        if(prob_uni_words[token]==0):\n",
    "            temp += log(prob_uni_words[token]+ep)\n",
    "        else:\n",
    "            temp += log(prob_uni_words[token])\n",
    "    temp += log(prob_uni_words[\"</s>\"])\n",
    "    temp = (-temp)/N\n",
    "    perplexity[id] = exp(temp)\n",
    "    pp += perplexity[id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10715500743194.346\n"
     ]
    }
   ],
   "source": [
    "maxi = 0\n",
    "for i in range(len(perplexity)):\n",
    "\n",
    "    maxi = max(perplexity[i],maxi)\n",
    "    # print(perplexity[i])\n",
    "print(maxi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Unigram Model without smoothing is:  255029160.07513976\n"
     ]
    }
   ],
   "source": [
    "Unigram_pp = pp/len(test_corpus)\n",
    "print(\"Perplexity of Unigram Model without smoothing is: \", Unigram_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66110\n",
      "72975\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for id in processed_corpus:\n",
    "    for token in processed_corpus[id]:\n",
    "        vocab.add(token)\n",
    "print(len(vocab))\n",
    "for id in test_corpus:\n",
    "    for token in test_corpus[id]:\n",
    "        vocab.add(token)\n",
    "print(len(vocab))\n",
    "V = len(vocab) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uni_sm_words = {}\n",
    "prob_uni_sm_words[\"<s>\"] = (unigram_counts[\"<s>\"] + 1) / (N_train + V)\n",
    "prob_uni_sm_words[\"</s>\"] = (unigram_counts[\"</s>\"] + 1) / (N_train + V)\n",
    "for token in test_tokens:\n",
    "        if token in unigram_counts:\n",
    "            prob_uni_sm_words[token] = (unigram_counts[token] + 1) / (N_train + V)\n",
    "        else:\n",
    "              prob_uni_sm_words[token] = 1 / (N_train + V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_sm = {}\n",
    "pp_sm = 0\n",
    "# We are neglecting the words that does not appear in the train data\n",
    "for id in test_corpus:\n",
    "    N = 2 + len(test_corpus[id])\n",
    "    temp = log(prob_uni_sm_words[\"<s>\"])\n",
    "    for token in test_corpus[id]:\n",
    "        temp += log(prob_uni_sm_words[token])\n",
    "    temp += log(prob_uni_sm_words[\"</s>\"])\n",
    "    temp=(-temp)/N\n",
    "    perplexity_sm[id] = exp(temp)\n",
    "    pp_sm += perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Unigram Model with Laplace Smoothing is:  1277.93160029543\n"
     ]
    }
   ],
   "source": [
    "Unigram_sm_pp = pp_sm/len(test_corpus)\n",
    "print(\"Perplexity of Unigram Model with Laplace Smoothing is: \", Unigram_sm_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = {}\n",
    "for id in processed_corpus:\n",
    "    tokens = processed_corpus[id]\n",
    "    size = len(tokens)\n",
    "    if((\"<s> \"+tokens[0]) not in bigram_counts):\n",
    "        bigram_counts[\"<s> \"+ tokens[0]] = 0\n",
    "    bigram_counts[\"<s> \"+tokens[0]] += 1\n",
    "    for i in range(0,size-1):\n",
    "        str = tokens[i] + \" \" + tokens[i+1]\n",
    "        if(str not in bigram_counts):\n",
    "            bigram_counts[str] = 0\n",
    "        bigram_counts[str] += 1\n",
    "    if ((tokens[size-1] + \" </s>\") not in bigram_counts):\n",
    "        bigram_counts[tokens[size-1] + \" </s>\"] = 0\n",
    "    bigram_counts[tokens[size-1] + \" </s>\"]+= 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "871874"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_bi_words = {}\n",
    "for id in test_corpus:\n",
    "    tokens = [\"<s>\"]\n",
    "    tokens += test_corpus[id]\n",
    "    tokens.append(\"</s>\")\n",
    "    size = len(tokens)\n",
    "    for i in range(0,size-1):\n",
    "        key = tokens[i]+ \" \"+ tokens[i+1]\n",
    "        if key in bigram_counts:\n",
    "            prob_bi_words[key] = bigram_counts[key] / unigram_counts[tokens[i]]\n",
    "        else:\n",
    "            prob_bi_words[key] = 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_perplexity = {}\n",
    "bi_pp = 0\n",
    "ep=1e-15\n",
    "# We are neglecting the words that does not appear in the train data\n",
    "for id in test_corpus:\n",
    "    N = 2 + len(test_corpus[id])\n",
    "    tokens = [\"<s>\"]\n",
    "    tokens += test_corpus[id]\n",
    "    tokens.append(\"</s>\")\n",
    "    size = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,size-1):\n",
    "        str = tokens[i] + \" \" + tokens[i+1]\n",
    "        if prob_bi_words[str]!=0:\n",
    "            temp += log(prob_bi_words[str])\n",
    "        else:\n",
    "            temp += log(prob_bi_words[str]+ep)\n",
    "    temp = (-temp)/N\n",
    "    bi_perplexity[id] = exp(temp)\n",
    "    bi_pp += bi_perplexity[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Bigram Model without smoothing is:  31069869118.23472\n"
     ]
    }
   ],
   "source": [
    "Bigram_pp = bi_pp/len(test_corpus)\n",
    "print(\"Perplexity of Bigram Model without smoothing is: \", Bigram_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_bi_sm_words = {}\n",
    "for key in bigram_counts:\n",
    "    w1,w2 = key.split(\" \")\n",
    "    if(key not in prob_bi_sm_words):\n",
    "        prob_bi_sm_words[key] = (bigram_counts[key] + 1) / (unigram_counts[w1] + V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_perplexity_sm = {}\n",
    "bi_pp_sm = 0\n",
    "# We are neglecting the words that does not appear in the train data\n",
    "for id in test_corpus:\n",
    "    N = 2 + len(test_corpus[id])\n",
    "    tokens = [\"<s>\"]\n",
    "    tokens += test_corpus[id]\n",
    "    tokens.append(\"</s>\")\n",
    "    size = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,size-1):\n",
    "        str = tokens[i] + \" \" + tokens[i+1]\n",
    "        if(str in prob_bi_sm_words):\n",
    "            temp += log(prob_bi_sm_words[str])\n",
    "        elif (tokens[i] in unigram_counts):\n",
    "            p = 1 / (unigram_counts[tokens[i]] + V)\n",
    "            temp += log(p)\n",
    "        else:\n",
    "            p = 1/V\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    bi_perplexity_sm[id] = exp(temp)\n",
    "    bi_pp_sm += bi_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Bigram Model with smoothing is:  1985.1815331914747\n"
     ]
    }
   ],
   "source": [
    "Bigram_sm_pp = bi_pp_sm/len(test_corpus)\n",
    "print(\"Perplexity of Bigram Model with smoothing is: \", Bigram_sm_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_counts = {}\n",
    "for id in processed_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\"]\n",
    "    tokens += processed_corpus[id] + [\"</s>\", \"</s>\"]\n",
    "    size = len(tokens)\n",
    "    for i in range(0,size-2):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2]\n",
    "        if(str not in trigram_counts):\n",
    "            trigram_counts[str] = 0\n",
    "        trigram_counts[str] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2136765\n"
     ]
    }
   ],
   "source": [
    "print(len(trigram_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tri_words = {}\n",
    "for key in trigram_counts:\n",
    "    w1,w2,w3 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2\n",
    "    if (prev in bigram_counts):\n",
    "        prob_tri_words[key] = trigram_counts[key] / bigram_counts[prev]\n",
    "    else:\n",
    "        prob_tri_words[key] = trigram_counts[key] / unigram_counts[w2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_perplexity = {}\n",
    "tri_pp = 0\n",
    "ep=1e-15\n",
    "# We are neglecting the words that does not appear in the train data\n",
    "for id in test_corpus:\n",
    "    N = 4 + len(test_corpus[id])\n",
    "    tokens = [\"<s>\", \"<s>\"]\n",
    "    tokens += test_corpus[id] + [\"</s>\", \"</s>\"]\n",
    "    size = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,size-2):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2]\n",
    "        if(str in prob_tri_words):\n",
    "            temp += log(prob_tri_words[str])\n",
    "        else:\n",
    "            temp +=log(ep)\n",
    "    temp = (-temp)/N\n",
    "    tri_perplexity[id] = exp(temp)\n",
    "    tri_pp += tri_perplexity[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Trigram Model without smoothing is:  69139995101.5171\n"
     ]
    }
   ],
   "source": [
    "Trigram_pp = tri_pp/len(test_corpus)\n",
    "print(\"Perplexity of Trigram Model without smoothing is: \", Trigram_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigram Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tri_sm_words = {}\n",
    "for key in trigram_counts:\n",
    "    w1,w2,w3 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2\n",
    "    if (prev in bigram_counts):\n",
    "        prob_tri_words[key] = (trigram_counts[key] + 1) / (bigram_counts[prev] + V)\n",
    "    else:\n",
    "        prob_tri_words[key] = (trigram_counts[key] + 1) / (unigram_counts[w2] + V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_perplexity_sm = {}\n",
    "tri_pp_sm = 0\n",
    "# We are neglecting the words that does not appear in the train data\n",
    "for id in test_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\"]\n",
    "    tokens += test_corpus[id] + [\"</s>\", \"</s>\"]\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-2):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2]\n",
    "        if(str in prob_tri_sm_words):\n",
    "            temp += log(prob_tri_sm_words[str])\n",
    "        else:\n",
    "            prev = tokens[i] + \" \" + tokens[i+1]\n",
    "            if (prev in bigram_counts):\n",
    "                p = 1 /(bigram_counts[prev] + V)\n",
    "            elif (tokens[i+1] in unigram_counts):\n",
    "                p = 1 /(unigram_counts[tokens[i+1]] + V)\n",
    "            else:\n",
    "                p = 1/V\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    tri_perplexity_sm[id] = exp(temp)\n",
    "    tri_pp_sm += tri_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Trigram Model without smoothing is:  20458.98937238894\n"
     ]
    }
   ],
   "source": [
    "Trigram_sm_pp = tri_pp_sm/len(test_corpus)\n",
    "print(\"Perplexity of Trigram Model without smoothing is: \", Trigram_sm_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadgram_counts = {}\n",
    "for id in processed_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\", \"<s>\"]\n",
    "    tokens += processed_corpus[id] + [\"</s>\", \"</s>\", \"</s>\"]\n",
    "    size = len(tokens)\n",
    "    for i in range(0,size-3):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2] + \" \" + tokens[i+3]\n",
    "        if(str not in quadgram_counts):\n",
    "            quadgram_counts[str] = 0\n",
    "        quadgram_counts[str] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2910767\n"
     ]
    }
   ],
   "source": [
    "print(len(quadgram_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_quad_words = {}\n",
    "for key in quadgram_counts:\n",
    "    w1,w2,w3,w4 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2 + \" \" + w3\n",
    "    if (prev in trigram_counts):\n",
    "        prob_quad_words[key] = quadgram_counts[key] / trigram_counts[prev]\n",
    "    else:\n",
    "        prob_quad_words[key] = quadgram_counts[key] / unigram_counts[w3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_perplexity = {}\n",
    "quad_pp = 0\n",
    "ep=1e-15\n",
    "# We are neglecting the words that does not appear in the train data\n",
    "for id in test_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\",\"<s>\"]\n",
    "    tokens += test_corpus[id] + [\"</s>\", \"</s>\", \"</s>\"]\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-3):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2] + \" \" + tokens[i+3]\n",
    "        if(str in prob_quad_words):\n",
    "            temp += log(prob_quad_words[str])\n",
    "        else:\n",
    "            temp +=log(ep)\n",
    "    temp = (-temp)/N\n",
    "    quad_perplexity[id] = exp(temp)\n",
    "    quad_pp += quad_perplexity[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Quadgram Model without smoothing is:  292224555035.2341\n"
     ]
    }
   ],
   "source": [
    "Quadgram_pp = quad_pp/len(test_corpus)\n",
    "print(\"Perplexity of Quadgram Model without smoothing is: \", Quadgram_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadgram Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_quad_sm_words = {}\n",
    "for key in quadgram_counts:\n",
    "    w1,w2,w3,w4 = key.split(\" \")\n",
    "    prev = w1 + \" \" + w2 + \" \" + w3\n",
    "    if (prev in trigram_counts):\n",
    "        prob_quad_words[key] = (quadgram_counts[key] + 1) / (trigram_counts[prev] + V)\n",
    "    else:\n",
    "        prob_quad_words[key] = (quadgram_counts[key] + 1) / (unigram_counts[w3] + V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_perplexity_sm = {}\n",
    "quad_pp_sm = 0\n",
    "\n",
    "for id in test_corpus:\n",
    "    tokens = [\"<s>\", \"<s>\", \"<s>\"]\n",
    "    tokens += test_corpus[id] + [\"</s>\", \"</s>\", \"</s>\"]\n",
    "    N = len(tokens)\n",
    "    temp = 0\n",
    "    for i in range(0,N-3):\n",
    "        str = tokens[i] + \" \" + tokens[i+1] + \" \" + tokens[i+2] + \" \" + tokens[i+3]\n",
    "        if(str in prob_quad_sm_words):\n",
    "            temp += log(prob_quad_sm_words[str])\n",
    "        else:\n",
    "            prev = tokens[i] + \" \" + tokens[i+1] + \" \" +tokens[i+2]\n",
    "            if (prev in trigram_counts):\n",
    "                p = 1 /(trigram_counts[prev] + V)\n",
    "            elif ((tokens[i+1]+\" \" + tokens[i+2]) in bigram_counts):\n",
    "                p = 1 /(bigram_counts[(tokens[i+1]+\" \" + tokens[i+2])] + V)\n",
    "            elif (tokens[i+2] in unigram_counts):\n",
    "                p = 1/(unigram_counts[tokens[i+2]] + V)\n",
    "            else:\n",
    "                p = 1/V\n",
    "            temp += log(p)\n",
    "    temp = (-temp)/N\n",
    "    quad_perplexity_sm[id] = exp(temp)\n",
    "    quad_pp_sm += quad_perplexity_sm[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Quadgram Model with smoothing is:  13810.954894288125\n"
     ]
    }
   ],
   "source": [
    "Quadgram_sm_pp = quad_pp_sm/len(test_corpus)\n",
    "print(\"Perplexity of Quadgram Model with smoothing is: \", Quadgram_sm_pp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
